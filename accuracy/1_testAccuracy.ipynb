{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm, trange\n",
    "# from pyleetspeak import LeetSpeaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\humay\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\humay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\humay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pyleetspeak import LeetSpeaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyleetspeak 0.3.9 requires numpy==1.21.5, but you have numpy 1.26.2 which is incompatible.\n",
    "# pyleetspeak 0.3.9 requires scikit-learn==1.0.2, but you have scikit-learn 1.3.2 which is incompatible.\n",
    "# synthcity 0.2.9 requires numpy<1.24,>=1.20, but you have numpy 1.26.2 which is incompatible.\n",
    "# synthcity 0.2.9 requires pandas<2,>=1.4, but you have pandas 2.0.3 which is incompatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1tch\n"
     ]
    }
   ],
   "source": [
    "text_in = \"bitch\"\n",
    "leeter = LeetSpeaker(\n",
    "    change_prb=0.8, change_frq=0.6, mode=\"basic\", seed=0, verbose=False\n",
    ")\n",
    "leet_result = leeter.text2leet(text_in)\n",
    "print(leet_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232990</th>\n",
       "      <td>cockade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102118</th>\n",
       "      <td>partnersuche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210175</th>\n",
       "      <td>pottercast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260402</th>\n",
       "      <td>glamorize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232391</th>\n",
       "      <td>drey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37611</th>\n",
       "      <td>taz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55931</th>\n",
       "      <td>adieu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265626</th>\n",
       "      <td>obsid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75141</th>\n",
       "      <td>porfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28058</th>\n",
       "      <td>monaghan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83333 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word\n",
       "232990       cockade\n",
       "102118  partnersuche\n",
       "210175    pottercast\n",
       "260402     glamorize\n",
       "232391          drey\n",
       "...              ...\n",
       "37611            taz\n",
       "55931          adieu\n",
       "265626         obsid\n",
       "75141       porfolio\n",
       "28058       monaghan\n",
       "\n",
       "[83333 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 100k words from commonwords\n",
    "# get leetwords for all words\n",
    "common_df = pd.read_csv('../commonWords.csv')\n",
    "common_df = common_df.drop(columns=['count'])\n",
    "common_df_sample = common_df.sample(frac=0.25)\n",
    "common_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83333/83333 [00:02<00:00, 37334.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pyleetspeak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cockade</td>\n",
       "      <td>c0ck4d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partnersuche</td>\n",
       "      <td>p@rtn3rsuch3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pottercast</td>\n",
       "      <td>p0tterc4st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glamorize</td>\n",
       "      <td>gl@m0r1ze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drey</td>\n",
       "      <td>dr3y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word   pyleetspeak\n",
       "0       cockade       c0ck4d3\n",
       "1  partnersuche  p@rtn3rsuch3\n",
       "2    pottercast    p0tterc4st\n",
       "3     glamorize     gl@m0r1ze\n",
       "4          drey          dr3y"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get pyleet words\n",
    "leeter = LeetSpeaker(\n",
    "    change_prb=0.8, change_frq=0.6, mode=\"basic\", seed=0, verbose=False\n",
    ")\n",
    "common_leet_dict = {'word':[], 'pyleetspeak':[]}\n",
    "\n",
    "for i in trange(len(common_df_sample['word'].values)):\n",
    "    word = common_df_sample['word'].values[i]\n",
    "    leetword = leeter.text2leet(word)\n",
    "    common_leet_dict['word'].append(word)\n",
    "    common_leet_dict['pyleetspeak'].append(leetword)\n",
    "\n",
    "common_leet_df = pd.DataFrame(common_leet_dict)\n",
    "common_leet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25000 entries, 67731 to 13377\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   word         25000 non-null  object\n",
      " 1   pyleetspeak  25000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 585.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#get leet words using the miner\n",
    "#first get leet substitutions for a subset of the dataframe, then test accuracy on the other subset\n",
    "train, test = train_test_split(common_leet_df, test_size=0.30)\n",
    "test.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build frequent pattern/substitions list from training dataset\n",
    "import LeetMining as lm\n",
    "from pathlib import Path\n",
    "import json\n",
    "leet_fp = {}\n",
    "\n",
    "if Path('pyleetspeak_leetDict.json').exists(): # if dictionary already exists, load from folder\n",
    "    with open('pyleetspeak_leetDict.json') as json_file:\n",
    "        leet_fp = json.load(json_file)\n",
    "else:\n",
    "    lm.setupLeetDict()\n",
    "    trainLeet = {'word':[], 'pyleetspeak':[], 'minedLeet':[], 'candidates':[]}\n",
    "\n",
    "    for i in trange(5000):  #len(train['word'].values)): # running for a smaller subset , most likely will cover all cases\n",
    "        trainLeet['word'].append(train['word'].values[i])\n",
    "        trainLeet['pyleetspeak'].append(train['pyleetspeak'].values[i])\n",
    "\n",
    "        leetWords = lm.getLeetWordList(train['pyleetspeak'].values[i])\n",
    "        trainLeet['minedLeet'].append(leetWords)\n",
    "        candidates = []\n",
    "        for lword in leetWords:\n",
    "            possibleMatches = lm.getMatchList(lword)\n",
    "            candidates.append(possibleMatches)\n",
    "            possibleSubs = lm.getPossibleSubstitutions(lword, possibleMatches)\n",
    "            lm.updateLeetDict(possibleSubs)\n",
    "        trainLeet['candidates'].append(candidates)\n",
    "    train_result_df = pd.DataFrame(trainLeet)\n",
    "    train_result_df.head()\n",
    "    leet_fp = lm.getLeetDict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': {'0': 372, '3': 402, '4': 266, '@': 284, '_': 278, '1': 348},\n",
       " 'B': {'0': 40, '4': 20, '3': 38, '1': 36, '_': 40, '@': 20},\n",
       " 'C': {'3': 35, '@': 26, '4': 12, '_': 24, '1': 29, '0': 38},\n",
       " 'D': {'0': 46, '3': 47, '4': 33, '@': 33, '_': 51, '1': 34},\n",
       " 'E': {'3': 514, '0': 299, '1': 245, '_': 216, '@': 145, '4': 158},\n",
       " 'F': {'0': 29, '@': 23, '_': 27, '1': 21, '3': 23, '4': 13},\n",
       " 'G': {'3': 53, '_': 41, '0': 45, '1': 39, '@': 30, '4': 18},\n",
       " 'H': {'3': 34, '0': 44, '@': 24, '_': 28, '4': 23, '1': 29},\n",
       " 'I': {'1': 358, '0': 254, '@': 120, '3': 246, '4': 107, '_': 190},\n",
       " 'J': {'3': 11, '_': 10, '1': 8, '@': 7, '4': 3, '0': 9},\n",
       " 'K': {'0': 26, '3': 23, '@': 22, '_': 18, '4': 11, '1': 31},\n",
       " 'L': {'0': 69, '3': 61, '@': 44, '_': 38, '1': 53, '4': 29},\n",
       " 'M': {'4': 31, '3': 41, '@': 33, '_': 45, '1': 41, '0': 48},\n",
       " 'N': {'0': 74, '3': 83, '@': 37, '4': 42, '_': 61, '1': 57},\n",
       " 'O': {'0': 397, '3': 289, '@': 134, '1': 265, '4': 146, '_': 211},\n",
       " 'P': {'4': 30, '3': 36, '_': 38, '1': 33, '@': 48, '0': 41},\n",
       " 'Q': {'_': 3, '4': 1, '0': 1, '3': 1},\n",
       " 'R': {'0': 66, '1': 64, '3': 88, '@': 28, '4': 32, '_': 54},\n",
       " 'S': {'0': 99, '3': 92, '4': 66, '@': 56, '_': 61, '1': 88},\n",
       " 'T': {'0': 75, '3': 77, '@': 53, '4': 52, '_': 65, '1': 62},\n",
       " 'U': {'_': 163, '0': 175, '@': 65, '3': 163, '1': 149, '4': 74},\n",
       " 'V': {'3': 11, '_': 19, '4': 5, '1': 17, '@': 9, '0': 21},\n",
       " 'W': {'3': 28, '4': 15, '_': 20, '@': 23, '1': 19, '0': 28},\n",
       " 'X': {'3': 6, '4': 4, '_': 9, '@': 4, '1': 6, '0': 5},\n",
       " 'Y': {'3': 61, '_': 46, '4': 38, '0': 49, '@': 35, '1': 49},\n",
       " 'Z': {'@': 7, '4': 6, '3': 7, '_': 15, '1': 5, '0': 7}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mined frequent patterns\n",
    "leet_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect training results - leet dict and the result table\n",
    "if not Path('pyleetspeak_leetDict.json').exists():\n",
    "    with open(\"pyleetspeak_leetDict.json\", \"w\") as outfile: \n",
    "        json.dump(lm.getLeetDict(), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the frequent pattern list to detect and de-leetify the pyleetspeak words. Compare with the original and test accuracy.\n",
    "\n",
    "# Use the existing leetDict to get substitutions and leet transformations for new reply\n",
    "\n",
    "test_result = {'word':[], 'pyleetspeak':[], 'minedLeet':[], 'BestMatches':[], 'correct': []}\n",
    "\n",
    "for i in trange(5000):#  len(test['reply'].values)): # running for a smaller subset , most likely will cover all cases\n",
    "    test_result['word'].append(test['word'].values[i])\n",
    "    test_result['pyleetspeak'].append(test['pyleetspeak'].values[i])\n",
    "\n",
    "    leetWords = lm.getLeetWordList(test['pyleetspeak'].values[i])\n",
    "    test_result['minedLeet'].append(leetWords)\n",
    "    bestMatches = []\n",
    "    corrects = []\n",
    "\n",
    "    for lword in leetWords:\n",
    "        bestMatch = lm.getBestMatch(lword, leet_fp)\n",
    "        bestMatches.append(bestMatch)\n",
    "        if bestMatch.upper() == test['word'].values[i].upper():\n",
    "            corrects.append(\"yes\")\n",
    "        else:\n",
    "            corrects.append(\"no\")\n",
    "        \n",
    "    if len(bestMatches) > 0:\n",
    "        test_result['BestMatches'].append(bestMatches[0])\n",
    "        test_result['correct'].append(corrects[0])\n",
    "    else:\n",
    "        test_result['BestMatches'].append(None)\n",
    "        test_result['correct'].append(None)\n",
    "\n",
    "\n",
    "    # polarity_scores = polarity_scores_roberta(newReply)\n",
    "    # test2_result['Neg'].append(polarity_scores['roberta_neg'])\n",
    "    # test2_result['Neu'].append(polarity_scores['roberta_neu'])\n",
    "    # test2_result['Pos'].append(polarity_scores['roberta_pos'])\n",
    "\n",
    "test_result_df = pd.DataFrame(test_result)\n",
    "#test_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pyleetspeak</th>\n",
       "      <th>minedLeet</th>\n",
       "      <th>BestMatches</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lrapa</td>\n",
       "      <td>lr@p@</td>\n",
       "      <td>[lr@p@]</td>\n",
       "      <td>lrApA</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>originals</td>\n",
       "      <td>0r1g1n4ls</td>\n",
       "      <td>[0r1g1n4ls]</td>\n",
       "      <td>OrIgInAls</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aggravating</td>\n",
       "      <td>@ggr4vat1ng</td>\n",
       "      <td>[@ggr4vat1ng]</td>\n",
       "      <td>AggrAvatIng</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gamessiemens</td>\n",
       "      <td>g@m3ss13mens</td>\n",
       "      <td>[g@m3ss13mens]</td>\n",
       "      <td>gAmEssIEmens</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>luedenscheid</td>\n",
       "      <td>luedensche1d</td>\n",
       "      <td>[luedensche1d]</td>\n",
       "      <td>luedenscheId</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>indierock</td>\n",
       "      <td>1nd13rock</td>\n",
       "      <td>[1nd13rock]</td>\n",
       "      <td>IndIErock</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>rpgamer</td>\n",
       "      <td>rpg@m3r</td>\n",
       "      <td>[rpg@m3r]</td>\n",
       "      <td>rpgAmEr</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>anaesthesiology</td>\n",
       "      <td>4n43sth3s10l0gy</td>\n",
       "      <td>[4n43sth3s10l0gy]</td>\n",
       "      <td>AnAEsthEsIOlOgy</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>dietikon</td>\n",
       "      <td>di3tik0n</td>\n",
       "      <td>[di3tik0n]</td>\n",
       "      <td>diEtikOn</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>spitzbergen</td>\n",
       "      <td>sp1tzb3rg3n</td>\n",
       "      <td>[sp1tzb3rg3n]</td>\n",
       "      <td>spItzbErgEn</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2816 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word      pyleetspeak          minedLeet      BestMatches  \\\n",
       "1               lrapa            lr@p@            [lr@p@]            lrApA   \n",
       "4           originals        0r1g1n4ls        [0r1g1n4ls]        OrIgInAls   \n",
       "5         aggravating      @ggr4vat1ng      [@ggr4vat1ng]      AggrAvatIng   \n",
       "6        gamessiemens     g@m3ss13mens     [g@m3ss13mens]     gAmEssIEmens   \n",
       "7        luedenscheid     luedensche1d     [luedensche1d]     luedenscheId   \n",
       "...               ...              ...                ...              ...   \n",
       "4995        indierock        1nd13rock        [1nd13rock]        IndIErock   \n",
       "4996          rpgamer          rpg@m3r          [rpg@m3r]          rpgAmEr   \n",
       "4997  anaesthesiology  4n43sth3s10l0gy  [4n43sth3s10l0gy]  AnAEsthEsIOlOgy   \n",
       "4998         dietikon         di3tik0n         [di3tik0n]         diEtikOn   \n",
       "4999      spitzbergen      sp1tzb3rg3n      [sp1tzb3rg3n]      spItzbErgEn   \n",
       "\n",
       "     correct  \n",
       "1        yes  \n",
       "4        yes  \n",
       "5        yes  \n",
       "6        yes  \n",
       "7        yes  \n",
       "...      ...  \n",
       "4995     yes  \n",
       "4996     yes  \n",
       "4997     yes  \n",
       "4998     yes  \n",
       "4999     yes  \n",
       "\n",
       "[2816 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null = test_result_df[test_result_df['correct'] !='yes']\n",
    "null = null[null['correct'] !='no']\n",
    "null = null[null['word'].str.len() >= 15]\n",
    "#test_result_df['correct']\n",
    "test_result_df[test_result_df['correct'] =='yes']\n",
    "#no - try to match words that are already in the dictionary, if can't match, do direct substitution, mostly words  that resemble(close to) some words but not in dictionary\n",
    "#none - word lengths>=15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_result_df.to_csv(\"pyleet_accuracy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "#from LeetMining import getBestMatch\n",
    "spell = SpellChecker()\n",
    "spell.candidates('early-stage') # hyphenated words don't have candidates\n",
    "#lm.getBestMatch('early-stage', leet_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note think about running test for twitter again ? if I have time, made some changes in the bestmatches function, like defaulting to direct substitution\n",
    "#might not be a good idea, fp list is not good enough to be relying directly on the list\n",
    "#todo: save accuracy test df for result analysys later, run the same test for profanity list, run test on reddit, start with the dictionary\n",
    "#leet_fp2['0']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
