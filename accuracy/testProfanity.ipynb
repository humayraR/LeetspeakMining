{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm, trange\n",
    "# from pyleetspeak import LeetSpeaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build frequent pattern/substitions list from training dataset\n",
    "import LeetMining as lm\n",
    "import json\n",
    "leet_fp = {}\n",
    "with open('pyleetspeak_leetDict.json') as json_file:\n",
    "    leet_fp = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': {'0': 372, '3': 402, '4': 266, '@': 284, '_': 278, '1': 348},\n",
       " 'B': {'0': 40, '4': 20, '3': 38, '1': 36, '_': 40, '@': 20},\n",
       " 'C': {'3': 35, '@': 26, '4': 12, '_': 24, '1': 29, '0': 38},\n",
       " 'D': {'0': 46, '3': 47, '4': 33, '@': 33, '_': 51, '1': 34},\n",
       " 'E': {'3': 514, '0': 299, '1': 245, '_': 216, '@': 145, '4': 158},\n",
       " 'F': {'0': 29, '@': 23, '_': 27, '1': 21, '3': 23, '4': 13},\n",
       " 'G': {'3': 53, '_': 41, '0': 45, '1': 39, '@': 30, '4': 18},\n",
       " 'H': {'3': 34, '0': 44, '@': 24, '_': 28, '4': 23, '1': 29},\n",
       " 'I': {'1': 358, '0': 254, '@': 120, '3': 246, '4': 107, '_': 190},\n",
       " 'J': {'3': 11, '_': 10, '1': 8, '@': 7, '4': 3, '0': 9},\n",
       " 'K': {'0': 26, '3': 23, '@': 22, '_': 18, '4': 11, '1': 31},\n",
       " 'L': {'0': 69, '3': 61, '@': 44, '_': 38, '1': 53, '4': 29},\n",
       " 'M': {'4': 31, '3': 41, '@': 33, '_': 45, '1': 41, '0': 48},\n",
       " 'N': {'0': 74, '3': 83, '@': 37, '4': 42, '_': 61, '1': 57},\n",
       " 'O': {'0': 397, '3': 289, '@': 134, '1': 265, '4': 146, '_': 211},\n",
       " 'P': {'4': 30, '3': 36, '_': 38, '1': 33, '@': 48, '0': 41},\n",
       " 'Q': {'_': 3, '4': 1, '0': 1, '3': 1},\n",
       " 'R': {'0': 66, '1': 64, '3': 88, '@': 28, '4': 32, '_': 54},\n",
       " 'S': {'0': 99, '3': 92, '4': 66, '@': 56, '_': 61, '1': 88, '5': 1},\n",
       " 'T': {'0': 75, '3': 77, '@': 53, '4': 52, '_': 65, '1': 62, '+': 1, '7': 1},\n",
       " 'U': {'_': 163, '0': 175, '@': 65, '3': 163, '1': 149, '4': 74},\n",
       " 'V': {'3': 11, '_': 19, '4': 5, '1': 17, '@': 9, '0': 21},\n",
       " 'W': {'3': 28, '4': 15, '_': 20, '@': 23, '1': 19, '0': 28},\n",
       " 'X': {'3': 6, '4': 4, '_': 9, '@': 4, '1': 6, '0': 5},\n",
       " 'Y': {'3': 61, '_': 46, '4': 38, '0': 49, '@': 35, '1': 49},\n",
       " 'Z': {'@': 7, '4': 6, '3': 7, '_': 15, '1': 5, '0': 7}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mined frequent patterns\n",
    "leet_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>canonical_form_1</th>\n",
       "      <th>canonical_form_2</th>\n",
       "      <th>canonical_form_3</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>severity_rating</th>\n",
       "      <th>severity_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@55</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ssfcker</td>\n",
       "      <td>fuck</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>sexual orientation / gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ssfucker</td>\n",
       "      <td>fuck</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>sexual orientation / gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ssfvcker</td>\n",
       "      <td>fuck</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>sexual orientation / gender</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@sshole</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0ral seks</td>\n",
       "      <td>sex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0ral sex</td>\n",
       "      <td>sex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0rg@sm</td>\n",
       "      <td>orgasm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0rgasms</td>\n",
       "      <td>orgasm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sexual anatomy / sexual acts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text canonical_form_1 canonical_form_2 canonical_form_3  \\\n",
       "0         69               69              NaN              NaN   \n",
       "1        @55              ass              NaN              NaN   \n",
       "2   @ssfcker             fuck              ass              NaN   \n",
       "3  @ssfucker             fuck              ass              NaN   \n",
       "4  @ssfvcker             fuck              ass              NaN   \n",
       "5    @sshole              ass              NaN              NaN   \n",
       "6  0ral seks              sex              NaN              NaN   \n",
       "7   0ral sex              sex              NaN              NaN   \n",
       "8     0rg@sm           orgasm              NaN              NaN   \n",
       "9    0rgasms           orgasm              NaN              NaN   \n",
       "\n",
       "                     category_1                   category_2 category_3  \\\n",
       "0  sexual anatomy / sexual acts                          NaN        NaN   \n",
       "1  sexual anatomy / sexual acts                          NaN        NaN   \n",
       "2  sexual anatomy / sexual acts  sexual orientation / gender        NaN   \n",
       "3  sexual anatomy / sexual acts  sexual orientation / gender        NaN   \n",
       "4  sexual anatomy / sexual acts  sexual orientation / gender        NaN   \n",
       "5  sexual anatomy / sexual acts                          NaN        NaN   \n",
       "6  sexual anatomy / sexual acts                          NaN        NaN   \n",
       "7  sexual anatomy / sexual acts                          NaN        NaN   \n",
       "8  sexual anatomy / sexual acts                          NaN        NaN   \n",
       "9  sexual anatomy / sexual acts                          NaN        NaN   \n",
       "\n",
       "   severity_rating severity_description  \n",
       "0              1.0                 Mild  \n",
       "1              1.0                 Mild  \n",
       "2              2.8               Severe  \n",
       "3              2.8               Severe  \n",
       "4              2.4               Strong  \n",
       "5              1.6               Strong  \n",
       "6              1.0                 Mild  \n",
       "7              1.8               Strong  \n",
       "8              1.0                 Mild  \n",
       "9              1.0                 Mild  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and pre-process test data\n",
    "profanity_df = pd.read_csv('profanity_en.csv')\n",
    "profanity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(profanity_df['text'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1598/1598 [01:56<00:00, 13.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>canonical_form_1</th>\n",
       "      <th>canonical_form_2</th>\n",
       "      <th>canonical_form_3</th>\n",
       "      <th>minedLeet</th>\n",
       "      <th>BestMatches</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@55</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ssfcker</td>\n",
       "      <td>fuck</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@ssfcker]</td>\n",
       "      <td>[Assfcker]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ssfucker</td>\n",
       "      <td>fuck</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@ssfucker]</td>\n",
       "      <td>[Assfucker]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ssfvcker</td>\n",
       "      <td>fuck</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@ssfvcker]</td>\n",
       "      <td>[Assfvcker]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text canonical_form_1 canonical_form_2 canonical_form_3    minedLeet  \\\n",
       "0         69               69              NaN              NaN           []   \n",
       "1        @55              ass              NaN              NaN           []   \n",
       "2   @ssfcker             fuck              ass              NaN   [@ssfcker]   \n",
       "3  @ssfucker             fuck              ass              NaN  [@ssfucker]   \n",
       "4  @ssfvcker             fuck              ass              NaN  [@ssfvcker]   \n",
       "\n",
       "   BestMatches correct  \n",
       "0           []      []  \n",
       "1           []      []  \n",
       "2   [Assfcker]   [yes]  \n",
       "3  [Assfucker]   [yes]  \n",
       "4  [Assfvcker]   [yes]  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the frequent pattern list to detect and de-leetify the leet words from profanity csv\n",
    "import re\n",
    "# Use the existing leetDict to get substitutions and leet transformations for new reply\n",
    "def valid_answer(txt1, txt2, txt3, ans):\n",
    "    cond1 = isinstance(txt1, str) and txt1.upper() in ans.upper()\n",
    "    cond2 = isinstance(txt2, str) and txt2.upper() in ans.upper()\n",
    "    cond3 = isinstance(txt3, str) and txt3.upper() in ans.upper()\n",
    "\n",
    "    return cond1 or cond2 or cond3\n",
    "\n",
    "test_result = {'text':[], 'canonical_form_1':[], 'canonical_form_2':[], 'canonical_form_3':[], 'minedLeet':[], 'BestMatches':[], 'correct': []}\n",
    "\n",
    "for i in trange(len(profanity_df['text'].values)):\n",
    "    test_result['text'].append(profanity_df['text'].values[i])\n",
    "    test_result['canonical_form_1'].append(profanity_df['canonical_form_1'].values[i])\n",
    "    test_result['canonical_form_2'].append(profanity_df['canonical_form_2'].values[i])\n",
    "    test_result['canonical_form_3'].append(profanity_df['canonical_form_3'].values[i])\n",
    "\n",
    "    leetWords = lm.getLeetWordList(profanity_df['text'].values[i])\n",
    "    test_result['minedLeet'].append(leetWords)\n",
    "    bestMatches = []\n",
    "    corrects = []\n",
    "\n",
    "    for lword in leetWords:\n",
    "        bestMatch = lm.getBestMatch(lword, leet_fp)\n",
    "        bestMatches.append(bestMatch)\n",
    "        if valid_answer(profanity_df['canonical_form_1'].values[i], profanity_df['canonical_form_2'].values[i], profanity_df['canonical_form_3'].values[i], bestMatch):\n",
    "            corrects.append(\"yes\")\n",
    "        else:\n",
    "            corrects.append(\"no\")\n",
    "        \n",
    "    if len(bestMatches) > 0:\n",
    "        test_result['BestMatches'].append(bestMatches)\n",
    "        test_result['correct'].append(corrects)\n",
    "    else:\n",
    "        test_result['BestMatches'].append([])\n",
    "        test_result['correct'].append([])\n",
    "\n",
    "test_result_df = pd.DataFrame(test_result)\n",
    "test_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>canonical_form_1</th>\n",
       "      <th>canonical_form_2</th>\n",
       "      <th>canonical_form_3</th>\n",
       "      <th>minedLeet</th>\n",
       "      <th>BestMatches</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@55</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abbie</td>\n",
       "      <td>abraham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>abeed</td>\n",
       "      <td>abeed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aboe</td>\n",
       "      <td>abo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>wnker</td>\n",
       "      <td>wank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>wop</td>\n",
       "      <td>wop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>wophead</td>\n",
       "      <td>wop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>zip in the wire</td>\n",
       "      <td>zipperhead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>zipperhead</td>\n",
       "      <td>zipperhead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1288 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text canonical_form_1 canonical_form_2 canonical_form_3  \\\n",
       "0                  69               69              NaN              NaN   \n",
       "1                 @55              ass              NaN              NaN   \n",
       "19              abbie          abraham              NaN              NaN   \n",
       "20              abeed            abeed              NaN              NaN   \n",
       "21               aboe              abo              NaN              NaN   \n",
       "...               ...              ...              ...              ...   \n",
       "1593            wnker             wank              NaN              NaN   \n",
       "1594              wop              wop              NaN              NaN   \n",
       "1595          wophead              wop              NaN              NaN   \n",
       "1596  zip in the wire       zipperhead              NaN              NaN   \n",
       "1597       zipperhead       zipperhead              NaN              NaN   \n",
       "\n",
       "     minedLeet BestMatches correct  \n",
       "0           []          []      []  \n",
       "1           []          []      []  \n",
       "19          []          []      []  \n",
       "20          []          []      []  \n",
       "21          []          []      []  \n",
       "...        ...         ...     ...  \n",
       "1593        []          []      []  \n",
       "1594        []          []      []  \n",
       "1595        []          []      []  \n",
       "1596        []          []      []  \n",
       "1597        []          []      []  \n",
       "\n",
       "[1288 rows x 7 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null = test_result_df[test_result_df['correct'] !='yes']\n",
    "# null = null[null['correct'] !='no']\n",
    "# null = null[null['word'].str.len() >= 15]\n",
    "#test_result_df['correct']\n",
    "#test_result_df[test_result_df['correct'].values is None]\n",
    "#'yes' in test_result_df['correct'].values[0]\n",
    "test_result_df[test_result_df['minedLeet'].str.len()==0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>canonical_form_1</th>\n",
       "      <th>canonical_form_2</th>\n",
       "      <th>canonical_form_3</th>\n",
       "      <th>minedLeet</th>\n",
       "      <th>BestMatches</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ssfcker</td>\n",
       "      <td>fuck</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@ssfcker]</td>\n",
       "      <td>[Assfcker]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ssfucker</td>\n",
       "      <td>fuck</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@ssfucker]</td>\n",
       "      <td>[Assfucker]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ssfvcker</td>\n",
       "      <td>fuck</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@ssfvcker]</td>\n",
       "      <td>[Assfvcker]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@sshole</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@sshole]</td>\n",
       "      <td>[Asshole]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0ral seks</td>\n",
       "      <td>sex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0ral]</td>\n",
       "      <td>[Oral]</td>\n",
       "      <td>[no]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>we1back</td>\n",
       "      <td>wetback</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[we1back]</td>\n",
       "      <td>[wetback]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>wh0r3</td>\n",
       "      <td>whore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[wh0r3]</td>\n",
       "      <td>[whOrE]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>wh0re</td>\n",
       "      <td>whore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[wh0re]</td>\n",
       "      <td>[whOre]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>whor3</td>\n",
       "      <td>whore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[whor3]</td>\n",
       "      <td>[whorE]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>willy-whacker</td>\n",
       "      <td>willy-whacker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[willy-whacker]</td>\n",
       "      <td>[willy-whacker]</td>\n",
       "      <td>[yes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               text canonical_form_1 canonical_form_2 canonical_form_3  \\\n",
       "2          @ssfcker             fuck              ass              NaN   \n",
       "3         @ssfucker             fuck              ass              NaN   \n",
       "4         @ssfvcker             fuck              ass              NaN   \n",
       "5           @sshole              ass              NaN              NaN   \n",
       "6         0ral seks              sex              NaN              NaN   \n",
       "...             ...              ...              ...              ...   \n",
       "1574        we1back          wetback              NaN              NaN   \n",
       "1580          wh0r3            whore              NaN              NaN   \n",
       "1581          wh0re            whore              NaN              NaN   \n",
       "1586          whor3            whore              NaN              NaN   \n",
       "1590  willy-whacker    willy-whacker              NaN              NaN   \n",
       "\n",
       "            minedLeet      BestMatches correct  \n",
       "2          [@ssfcker]       [Assfcker]   [yes]  \n",
       "3         [@ssfucker]      [Assfucker]   [yes]  \n",
       "4         [@ssfvcker]      [Assfvcker]   [yes]  \n",
       "5           [@sshole]        [Asshole]   [yes]  \n",
       "6              [0ral]           [Oral]    [no]  \n",
       "...               ...              ...     ...  \n",
       "1574        [we1back]        [wetback]   [yes]  \n",
       "1580          [wh0r3]          [whOrE]   [yes]  \n",
       "1581          [wh0re]          [whOre]   [yes]  \n",
       "1586          [whor3]          [whorE]   [yes]  \n",
       "1590  [willy-whacker]  [willy-whacker]   [yes]  \n",
       "\n",
       "[310 rows x 7 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result_df[test_result_df['correct'].str.len()>0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1598/1598 [00:00<00:00, 91327.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes: 200\n",
      "No: 111\n",
      "None: 1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count_yes = 0\n",
    "count_no = 0\n",
    "count_none = 0\n",
    "for k in trange(len(test_result_df['text'].values)):\n",
    "    if test_result_df['correct'].values[k].count('yes') > 0:\n",
    "        count_yes+=test_result_df['correct'].values[k].count('yes')\n",
    "    if test_result_df['correct'].values[k].count('no') > 0:\n",
    "        count_no+=test_result_df['correct'].values[k].count('no')\n",
    "    if len(test_result_df['correct'].values[k]) ==0:\n",
    "        count_none+=1\n",
    "\n",
    "# len(test_result_df['correct'].values[0])\n",
    "print(\"Yes:\" , count_yes)\n",
    "print(\"No:\" , count_no)\n",
    "print(\"None:\" , count_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_df.to_csv('profanity_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#profanity list is a mix of leet and non-leet words, the none result is from non-leetwords, no is from phrases with leet but canonical form is incomplete, sometimes words are mix of different camouflaging techniques: misspell, leet, punctuations etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
